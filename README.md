# NetPlag-Stream : D√©tection Continue du Plagiat en Architecture Distribu√©e

## üìã Concept du Projet

**NetPlag-Stream** est un syst√®me de d√©tection de plagiat en temps r√©el utilisant des technologies Big Data. Il combine **Spark Streaming**, **HDFS**, et **Elasticsearch** pour analyser continuellement des documents acad√©miques (th√®ses, articles, rapports) et d√©tecter les similarit√©s avec un corpus de r√©f√©rence.

### Innovation
Premi√®re approche **streaming** pour la d√©tection de plagiat sur architecture distribu√©e, permettant une veille acad√©mique continue plut√¥t qu'une analyse batch ponctuelle.

---

## üèóÔ∏è Architecture

```
Documents Nouveaux ‚Üí Spark Streaming ‚Üí TF-IDF ‚Üí Similarit√© Cosinus
                           ‚Üì
                    HDFS (Stockage)
                           ‚Üì
                    Elasticsearch (Indexation)
                           ‚Üì
                    Dashboard Web (Visualisation)
```

**Technologies:**
- **Apache Spark 3.5.7** : Traitement distribu√© (batch + streaming)
- **HDFS** : Stockage distribu√© des documents et mod√®les
- **Elasticsearch 8.11.0** : Recherche et indexation temps r√©el
- **Flask** : Interface web interactive
- **Docker** : Conteneurisation des services

---

## ‚ö° D√©marrage Rapide (Guide Complet)

### Pr√©requis
- **Docker Desktop** (Windows/Linux)
- **Python 3.11**
- **Java 17**
- **8GB RAM minimum** (16GB recommand√©)

### √âtape 0 : Pr√©parer les Donn√©es

```powershell
# Assurez-vous d'avoir vos fichiers .txt de r√©f√©rence dans:
cd d:\app\Downloads\netplag_source
ls data\corpus_initial\*.txt  # Doit afficher vos documents
```

**Important:** Le corpus initial doit contenir des fichiers `.txt` avant de commencer.

### √âtape 1 : D√©marrer les Services Docker

```powershell
# Lancer les conteneurs (HDFS + Elasticsearch + Dashboard)
docker-compose up -d

# ‚è∞ Attendre 30 secondes que les services d√©marrent
Start-Sleep -Seconds 30

# V√©rifier que tous les services sont actifs
docker-compose ps
```

**Services lanc√©s:**
- NameNode HDFS : `http://localhost:9870`
- DataNode HDFS : `http://localhost:9866`
- Elasticsearch : `http://localhost:9200`
- Dashboard : `http://localhost:5000`

### √âtape 2 : Sortir HDFS du Mode S√©curis√©

```powershell
# CRITIQUE: D√©sactiver le SafeMode HDFS
docker exec namenode hdfs dfsadmin -safemode leave

# V√©rifier que HDFS est accessible
docker exec namenode hdfs dfs -ls /
```

### √âtape 3 : Installer D√©pendances Python

```powershell
# Installer les packages Python requis
pip install -r requirements.txt
```

### √âtape 4 : Cr√©er la Structure HDFS

```powershell
# Cr√©er les r√©pertoires HDFS
python scripts/0_migrate_to_hdfs.py

# ‚è∞ Temps estim√©: ~30 secondes
```

**Structure cr√©√©e:**
```
/netplag/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ corpus_initial/    # Corpus de r√©f√©rence
‚îÇ   ‚îú‚îÄ‚îÄ stream_input/      # Documents √† analyser
‚îÇ   ‚îî‚îÄ‚îÄ stream_source/     # Source pour simulation
‚îî‚îÄ‚îÄ storage/
    ‚îú‚îÄ‚îÄ idf_model/         # Mod√®le TF-IDF
    ‚îú‚îÄ‚îÄ reference_vectors/ # Vecteurs de r√©f√©rence
    ‚îú‚îÄ‚îÄ streaming_vectors/ # Vecteurs streaming
    ‚îî‚îÄ‚îÄ reports/           # Rapports d'analyse
```

### √âtape 5 : Migrer le Corpus de R√©f√©rence

```powershell
# Migration rapide des fichiers vers HDFS (500 fichiers par batch)
.\migrate_fast.ps1

# ‚è∞ Temps estim√©: 5-10 minutes selon la taille du corpus
# ATTENDRE la fin compl√®te avant de continuer
```

**V√©rifier la migration:**
```powershell
docker exec namenode hdfs dfs -ls /netplag/data/corpus_initial | Measure-Object -Line
```

### √âtape 6 : Initialiser le Mod√®le TF-IDF

```powershell
# Calcul des vecteurs TF-IDF pour le corpus de r√©f√©rence
python scripts/1_batch_init.py

# ‚è∞ Temps estim√©: 5-15 minutes selon le nombre de documents
```

**Ce script:**
1. Lit tous les documents du corpus
2. Nettoie le texte (minuscules, caract√®res sp√©ciaux)
3. Calcule les vecteurs TF-IDF (5000 dimensions)
4. Entra√Æne le mod√®le IDF
5. Sauvegarde mod√®le + vecteurs dans HDFS

**V√©rifier la cr√©ation du mod√®le:**
```powershell
docker exec namenode hdfs dfs -ls /netplag/storage/idf_model
docker exec namenode hdfs dfs -ls /netplag/storage/reference_vectors
```

---

## üéØ Utilisation

### Option A : Pipeline Automatis√© (RECOMMAND√â)

```powershell
# Lance le pipeline complet : Streaming + Analyse + Indexation
python scripts/8_full_streamprocess.py

# Le syst√®me est maintenant ACTIF!
# Laissez cette fen√™tre ouverte
```

**Fonctionnement:**
1. Surveille `/netplag/data/stream_input/` toutes les 5 secondes
2. D√©tecte automatiquement les nouveaux fichiers
3. Calcule la similarit√© avec le corpus de r√©f√©rence
4. Indexe les r√©sultats dans Elasticsearch
5. Disponible imm√©diatement dans le dashboard

### Tester le Syst√®me

```powershell
# Dans un NOUVEAU terminal, copier un fichier test
cp data\corpus_initial\2510.27168v1.txt data\stream_input\test_document.txt

# ‚è∞ Attendre ~10-15 secondes
# Le fichier sera automatiquement trait√©
```

**V√©rifier les r√©sultats:**
1. Ouvrir le dashboard : `http://localhost:5000`
2. Voir les statistiques mises √† jour
3. Chercher "test_document.txt" dans la table

### Option B : Pipeline Manuel (√âtape par √âtape)

```powershell
# Terminal 1: Lancer le streaming
python scripts/2_streaming_app.py

# Terminal 2: Analyser les r√©sultats (apr√®s avoir ajout√© des fichiers)
python scripts/4_plagiarism_analysis.py

# Terminal 3: Indexer dans Elasticsearch
python scripts/6_elasticsearch_indexer.py
```

### Ajouter des Documents √† Analyser

```powershell
# Copier vos fichiers .txt dans stream_input
cp mes_documents\*.txt data\stream_input\

# Les fichiers seront trait√©s automatiquement si Option A est active
```

### Acc√©der au Dashboard

```
http://localhost:5000
```

**Fonctionnalit√©s:**
- üìà Statistiques temps r√©el (cas d√©tect√©s, scores moyens)
- üìä Histogramme de distribution des similarit√©s
- üîç Recherche par nom de document
- üìã Tableau r√©capitulatif avec tri et pagination
- üîÑ Actualisation automatique toutes les 30s

---

## üõ†Ô∏è D√©pannage Rapide

### Probl√®me : Docker ne d√©marre pas

```powershell
# V√©rifier Docker
docker --version
docker ps

# Red√©marrer Docker Desktop puis
docker-compose up -d
```

### Probl√®me : HDFS en SafeMode

```powershell
# Sortir du SafeMode
docker exec namenode hdfs dfsadmin -safemode leave

# V√©rifier l'√©tat
docker exec namenode hdfs dfsadmin -report
```

### Probl√®me : Elasticsearch refuse la connexion

```powershell
# V√©rifier le statut
curl http://localhost:9200/_cluster/health

# Red√©marrer ES
docker-compose restart elasticsearch

# Voir les logs
docker-compose logs elasticsearch
```

### Probl√®me : "No reference vectors found"

```powershell
# Vous avez saut√© l'√©tape 6!
# R√©ex√©cuter l'initialisation
python scripts/1_batch_init.py

# V√©rifier la cr√©ation
docker exec namenode hdfs dfs -ls /netplag/storage/reference_vectors
```

### Probl√®me : Pipeline ne d√©tecte pas les fichiers

```powershell
# V√©rifier que les fichiers sont dans HDFS
docker exec namenode hdfs dfs -ls /netplag/data/stream_input

# Si vide, copier manuellement
docker exec namenode hdfs dfs -put /local/path/file.txt /netplag/data/stream_input/
```

---

## üî¨ Algorithme de D√©tection

**TF-IDF + Similarit√© Cosinus**

```
TF(t,d) = (Occurrences de t) / (Total mots)
IDF(t,D) = log(Total docs / Docs avec t)
TF-IDF(t,d,D) = TF(t,d) √ó IDF(t,D)

similarit√©(d1, d2) = (v1 ¬∑ v2) / (||v1|| √ó ||v2||)
```

**Seuils:**
- **> 0.7** : Plagiat potentiel ‚ö†Ô∏è
- **> 0.8** : Forte similarit√© üî¥
- **> 0.9** : Copie quasi-identique üö®

---

## üìÅ Structure des Fichiers Essentiels

### Configuration
- `config/hdfs_config.py` : Configuration HDFS et Spark
- `config/elasticsearch_config.py` : Configuration Elasticsearch
- `docker-compose.yml` : Orchestration des services Docker
- `requirements.txt` : D√©pendances Python

### Scripts Principaux
- **`0_migrate_to_hdfs.py`** : Cr√©ation structure HDFS
- **`1_batch_init.py`** : Initialisation mod√®le TF-IDF ‚ö†Ô∏è OBLIGATOIRE
- **`2_streaming_app.py`** : Traitement streaming temps r√©el
- **`4_plagiarism_analysis.py`** : Analyse batch compl√®te
- **`6_elasticsearch_indexer.py`** : Indexation Elasticsearch
- **`7_dashboard.py`** : Application web Flask
- **`8_full_streamprocess.py`** : ‚≠ê Pipeline complet automatis√©

### Utilitaires
- `similarity.py` : Calcul similarit√© cosinus
- **`migrate_fast.ps1`** : Migration rapide vers HDFS ‚ö†Ô∏è OBLIGATOIRE
- `3_simulateur.py` : Simulateur de flux continu (optionnel)

---

## üî¨ Algorithme de D√©tection

### 1. Vectorisation TF-IDF

**TF (Term Frequency):**
```
TF(t,d) = (Nombre d'occurrences de t dans d) / (Nombre total de mots dans d)
```

**IDF (Inverse Document Frequency):**
```
IDF(t,D) = log(Nombre total de documents / Nombre de documents contenant t)
```

**TF-IDF:**
```
TF-IDF(t,d,D) = TF(t,d) √ó IDF(t,D)
```

### 2. Similarit√© Cosinus

```
similarit√©(d1, d2) = (v1 ¬∑ v2) / (||v1|| √ó ||v2||)
```

O√π `v1` et `v2` sont les vecteurs TF-IDF des documents.

### 3. Seuil de D√©tection

- **Score > 0.7** : Plagiat potentiel d√©tect√©
- **Score > 0.8** : Forte similarit√© (alerte)
- **Score > 0.9** : Similarit√© tr√®s √©lev√©e (copie quasi-identique)

---

## üìä Exemple d'Utilisation

### Sc√©nario : Analyser 10 Nouveaux Articles

```powershell
# 1. D√©marrer le pipeline automatis√©
python scripts/8_full_streamprocess.py

# 2. Dans un autre terminal, copier les articles
cp articles_2024/*.txt data/stream_input/

# 3. Ouvrir le dashboard
start http://localhost:5000
```

**R√©sultats (apr√®s ~30 secondes):**
- Documents trait√©s : 10
- Cas de plagiat d√©tect√©s : 3
- Score moyen : 0.65
- Score maximum : 0.92 (alerte !)

**D√©tails disponibles:**
- Paires de documents similaires
- Scores de similarit√©
- Fichiers sources et r√©f√©rences

---

## üõ†Ô∏è Commandes Utiles

### Gestion Docker

```powershell
# Voir les logs des services
docker-compose logs -f

# Red√©marrer un service sp√©cifique
docker-compose restart namenode

# Arr√™ter tous les services
docker-compose down

# Supprimer volumes (‚ö†Ô∏è EFFACE LES DONN√âES)
docker-compose down -v
```

### HDFS

```powershell
# Lister les fichiers HDFS
docker exec namenode hdfs dfs -ls /netplag/data/corpus_initial

# Voir l'espace utilis√©
docker exec namenode hdfs dfs -du -h /netplag

# Copier un fichier depuis HDFS
docker exec namenode hdfs dfs -get /netplag/storage/reports/plagiarism_cases.json
```

### Elasticsearch

```powershell
# V√©rifier les indices
curl http://localhost:9200/_cat/indices?v

# Compter les documents index√©s
curl http://localhost:9200/plagiarism_reports/_count

# Rechercher des documents
curl http://localhost:9200/plagiarism_reports/_search?q=similarity_score:>0.8
```

---

## üéØ Cas d'Usage

### 1. Veille Acad√©mique Continue
- Surveillance automatique des nouvelles publications
- D√©tection de plagiat entre articles soumis
- Alerte en temps r√©el sur similarit√©s suspectes

### 2. Validation de Th√®ses/M√©moires
- Analyse batch de documents √©tudiants
- Comparaison avec corpus bibliographique
- G√©n√©ration de rapports d√©taill√©s

### 3. Conformit√© √âditoriale
- V√©rification avant publication
- D√©tection de r√©utilisation non cit√©e
- Tra√ßabilit√© des sources

---

## ‚öôÔ∏è Configuration Avanc√©e

### Modifier le Seuil de D√©tection

√âditer `scripts/2_streaming_app.py` ou `scripts/8_full_streamprocess.py` :

```python
# Ligne ~80
PLAGIARISM_THRESHOLD = 0.7  # Changer √† 0.6 ou 0.8
```

### Ajuster la Fr√©quence de Streaming

```python
# Ligne ~50
TRIGGER_INTERVAL = "5 seconds"  # Changer √† "10 seconds"
```

### Augmenter le Nombre de Features TF-IDF

√âditer `scripts/1_batch_init.py` :

```python
# Ligne ~60
hashingTF = HashingTF(inputCol="words", outputCol="rawFeatures", numFeatures=5000)
# Changer √† 10000 pour plus de pr√©cision
```

---

## üìà Performances

### Capacit√© Test√©e
- **Corpus de r√©f√©rence** : 500+ documents
- **Streaming** : 10 documents toutes les 5 secondes
- **Latence moyenne** : < 10 secondes par batch
- **Throughput** : ~120 documents/minute
- **Pr√©cision** : ~85% (seuil 0.7)

### Optimisations
- Vecteurs creux (SparseVector) pour √©conomie m√©moire
- Broadcast du corpus de r√©f√©rence (√©vite shuffle)
- Stockage Parquet (compression 10x)
- Indexation bulk Elasticsearch (1000 docs/batch)
- Checkpointing HDFS (tol√©rance aux pannes)

---

## üìö R√©f√©rences

### Articles Scientifiques
- "TF-IDF: A Statistical Interpretation" - Salton & McGill (1983)
- "Cosine Similarity in Information Retrieval" - Baeza-Yates (1999)
- "Plagiarism Detection: A Survey" - Alzahrani et al. (2012)

### Documentation Technique
- [Apache Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [HDFS Architecture Guide](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)
- [Elasticsearch Reference](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)

---

## ü§ù Contribution & Publication

**Publication Potentielle:**
> "NetPlag-Stream: A Real-Time Distributed Architecture for Academic Plagiarism Detection using Spark Streaming and Delta Lake"

**Axes de Recherche:**
- Architectures Big Data temps r√©el pour veille scientifique
- Optimisation du calcul de similarit√© √† grande √©chelle
- D√©tection s√©mantique avec transformers (BERT)
- Gestion incr√©mentale des mod√®les TF-IDF

---


## ‚ú® Auteurs

D√©velopp√© dans le cadre d'un projet Big Data sur la d√©tection de plagiat en architecture distribu√©e.

- Bellmir Yahya
- Ismaili Ayman
- Ait Abdou Ayman
- Chegdati Chouaib 

---

## ‚ö° Guide Complet Pas-√†-Pas

### 1. Pr√©parer les donn√©es
```powershell
# Vos fichiers .txt doivent √™tre dans:
data/corpus_initial/
```


