Title: Prediction of atomic H adsorption energies in metalloid doped MSSe (M = Mo/W) Janus layers: A combined DFT and machine learning study
URL: http://arxiv.org/abs/2511.16263v1
Published: 2025-11-20 11:45:03+00:00
----------------------------------------
Janus derivatives of 2H MX2 (M = Mo/W; X = S/Se), namely MSSe, have already been experimentally realized and explored for applications in photocatalysis, photovoltaics, and optoelectronics. Focusing on the photocatalytic properties of these layers, we investigate the adsorption of atomic hydrogen on the MSSe layers in the presence of metalloid dopants B, Si, and Ge. The layers in their pristine form exhibit positive adsorption energies, indicating an endothermic nature. Substitution of a dopant in the pristine MSSe layers alters the local symmetry, bonding character, and charge distribution, thereby increasing the number of active sites for hosting H adsorption and reducing the adsorption energy. We select distinct sites, both atomic and interstitial, for the substitution of dopants. The energetics of the H atom at various sites is studied to find the most favorable active site on the MSSe Janus layers. Our results based on density functional theory calculations show that the adsorption process becomes spontaneous and less attractive in the presence of atomic site dopant substitution, whereas the interstitial site results in an endothermic behavior. Moreover, having the data from DFT, we develop a supervised machine learning model for predicting the hydrogen adsorption energy. For this purpose, we utilize 23 elemental features of the atoms involved in the structure, thereby eliminating the need for DFT calculations in feature design. The dimensionality reduction technique, principal component analysis, is employed to reduce the dimensionality of the feature space, yielding independent features that are mutually orthogonal. The model is implemented as a multi-layer perceptron regressor with two hidden layers. The data augmentation technique is employed to artificially expand the dataset size, thereby enhancing the accuracy of the neural network model by 0.90% on the testing data.